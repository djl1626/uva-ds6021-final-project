
```{r}
library(tidyverse)
```

## Importing Data
```{r}
stars <- read.csv("C:\\Users\\saint\\Downloads\\Stars_clean_r.csv")
```

```{r}
#Removing index
stars = stars[,-1]
```

```{r}
#changing column names
names(stars) <- c("Temperature","Relative_Luminosity", "Relative_Radius", "Absolute_Magnitude","Color",
                   "Spectral_Class","Type")
```

## Looking at numerical variables vs. temperature (response)
```{r}
#Facet wrap of individual variables
stars2 <- gather(stars, key="predictor", value="value",
                 Relative_Luminosity, Relative_Radius, Absolute_Magnitude)
ggplot(stars2, aes(x=value, y=Temperature,color=predictor))+geom_point()+
  facet_wrap(~predictor,scales = "free_x")+scale_color_manual(values = c("Absolute_Magnitude" = "darkslateblue", "Relative_Luminosity" = "coral3", "Relative_Radius" = "cadetblue4"))+theme(legend.position = "none")
```

Looking at first few graphs, it is hard to see a linear relationship between variables.

# First Model (luminosity, radius, magnitude predicting temperature)
```{r}
#Building model
model1 <- lm(Temperature~Relative_Luminosity+Relative_Radius+Absolute_Magnitude, data = stars)
summary(model1)
```
The model has a very low R^2. Need to check assumptions now.

### Checking assumptions:
1. Residual plot
```{r}
stars_predict <- mutate(stars, predictions=fitted(model1),
                        resid=residuals(model1))
```

```{r}
ggplot(stars_predict, aes(x=predictions, y=resid))+geom_point()+geom_hline(yintercept=0, color = "red")
```
2. QQplot (4th assumption)
```{r}
ggplot(stars_predict, aes(sample=resid))+stat_qq()+stat_qq_line(color="red")
```

The first model defintely is not useful, it doesn't have a high R^2 and it does not pass some of the assumptions needed. Next, we transformed the variables using log.

# Transformations
```{r}
#Log Transformations (except magnitude due to negatives)
stars_t <- mutate(stars, Log_Luminosity = log(Relative_Luminosity), Log_Temperature = log(Temperature), Log_Radius = log(Relative_Radius), Magnitude = Absolute_Magnitude)
```


```{r}
stars_t2 <- gather(stars_t, key="predictor", value="value",
                  Log_Luminosity, Log_Radius, Magnitude)
```


```{r}
#New facet wrap of transformations
ggplot(stars_t2, aes(x=value, y=Log_Temperature,color=predictor))+geom_point()+
  facet_wrap(~predictor,scales = "free_x")
```
These graphs look a lot better than the original. Now need to build a model and check assumptions.


# New Model
```{r}
model_t <- lm(Log_Temperature~Log_Luminosity+Log_Radius+Magnitude, data = stars_t)
summary(model_t)
```
Model improved in terms of adjusted R^2 along with have significant p-values. Now need to check assumptions of the model.
### Assumptions transformation model:
```{r}
predict_t <- mutate(stars_t, predictions = fitted(model_t), resid=residuals(model_t))
```


```{r}
#Residual plot
ggplot(predict_t, aes(x=predictions, y=resid))+geom_point()+geom_hline(yintercept=0, color = "red")
```

```{r}
#qqplot
ggplot(predict_t, aes(sample=resid))+stat_qq()+stat_qq_line(color="red")
```
These also look a little bit better but have some patterns such as the qqplot deviated from the line at the extremes and the residual plot having groupings and not being random.


### checking for MC:
```{r}
stars_mc <- subset(stars_t, select = -c(Temperature, Relative_Luminosity, Relative_Radius, Absolute_Magnitude, Color,
                                         Spectral_Class,Type))
```

```{r}
cor_mat <- round(cor(stars_mc),2)
```

```{r}
library(ggcorrplot)
```

```{r}
ggcorrplot(cor_mat, lab=TRUE, type="lower", colors = c("cadetblue4","white","coral4"))
```

```{r}
#calcing VIFs
library(car)
vif(model_t)
```

There is a lot of multi-colinearity between variables, need to remove a variable.


# Taking out magnitude
```{r}
stars_nom <- mutate(stars, Log_Luminosity = log(Relative_Luminosity), Log_Temperature = log(Temperature), Log_Radius = log(Relative_Radius))
```


```{r}
stars_tn <- gather(stars_nom, key="predictor", value="value",
                  Log_Luminosity,Log_Radius)
```

```{r}
#Graphing predictors with response
ggplot(stars_tn, aes(x=value, y=Log_Temperature,color=predictor))+geom_point()+
  facet_wrap(~predictor,scales = "free_x") + scale_color_manual(values = c("Log_Luminosity" = "coral3", "Log_Radius" = "cadetblue4")) + theme(legend.position = "none")
```

New model:
```{r}
#New model with radius and luminosity predicting temperature (log)
model_n <- lm(Log_Temperature~Log_Radius+Log_Luminosity, data = stars_nom)
summary(model_n)
```
After taking out magnitude, the model's adjusted R^2 is around .5244 which is better.

```{r}
predict_nm <- mutate(stars_nom, predictions = fitted(model_n),
                     resid=residuals(model_n))
```


## Assumptions of new model
```{r}
#Residual plot of new model
ggplot(predict_nm, aes(x=predictions, y = resid))+geom_point()+geom_hline(yintercept=0,color="red")
```

```{r}
#qqplot of new model
ggplot(predict_nm, aes(sample=resid))+stat_qq()+stat_qq_line(color="red")
```
The assumptions look better but still the qqplot still has the tails that deviate from the line at the extremes. The residual plot seems to have more spread but does have some areas where its clumped. This shows that extreme values, the model might not predict as well.

# Checking Multi-colinearity of new model
```{r}
stars_mc2 <- subset(stars_t, select = -c(Temperature, Relative_Luminosity, Relative_Radius, Absolute_Magnitude, Color,
                                         Spectral_Class,Type, Magnitude))
```

```{r}
#creating correlation matrix
cor_mat2 <- round(cor(stars_mc2),2)
```

```{r}
cor_mat2
```


```{r}
car::vif(model_n)
```

The VIF lowered a lot but there is still a chance of multi-colinearity due to it being above 5.

```{r}
#plot of correlation matrix
ggcorrplot(cor_mat2, lab = TRUE, type = "lower", colors = c("cadetblue4","white","coral4"))
```

## Cross validation for testing with new data

Now want to test how the model does on new data using cross-validation.


```{r}
library(caret)
```

```{r}
control <- trainControl(method = "cv", number = 10)
```

```{r}
model_cv <- train(Log_Temperature~Log_Radius+Log_Luminosity, method = "lm",
                  trControl = control, data = stars_nom)
summary(model_cv)
```

```{r}
#Calculating RMSE
model_cv$results$RMSE
```
RMSE is 0.589 which shows on average, how much error will a prediction be off by.

# Predictions
```{r}
#Making prediction of first 3 rows
predict(model_n, newdata = stars_nom[1:3,], interval = "prediction", level = .95)
```

```{r}
#scaling predictions back 
exp(predict(model_n, newdata = stars_nom[1:3,]))

```

```{r}
#Confidence interval
exp(predict(model_n, newdata = stars_nom[1:3,], interval = "confidence", level = .95))
```

Made predictions based on the model using luminosity and radius as predictors of temperature. When comparing the predicted values to the observed values, the model was off by a little bit. 

The model is of some use but it is off a some when making predictions of temperature based off these predictors.
